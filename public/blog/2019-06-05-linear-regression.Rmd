---
title: "Introdução a Análise de Regressão Linear" 
author: Douglas Vinícius
date: '2019-06-17'
slug: linear-regression
categories:
  - Linear
  - R
  - Regressão
  - RStudio
tags:
  - linear
  - plot
  - R Markdown
  - regression
  - data
comments: no
showcomments: yes
showpagemeta: yes

---

# Revisão e Visão Geral

### *Podemos Predizer o preço da tarifa de metrô a partir do custo de uma fatia de pizza?*

Em 1964, Eric Bram


O modelo estatístico de regressão linear simples descreve a relação mais simples entre duas variáveis - uma linha reta.




Introdução completa à regressão linear em R
A regressão linear é usada para prever o valor de uma variável contínua Y com base em uma ou mais variáveis preditoras de entrada X. O objetivo é estabelecer uma fórmula matemática entre a variável resposta (Y) e as variáveis preditoras (Xs). Você pode usar essa fórmula para prever Y, quando apenas valores X são conhecidos.

1. Introdução à Regressão Linear
A regressão linear é uma das técnicas de modelagem preditiva mais utilizadas. O objetivo da regressão linear é encontrar uma equação matemática para uma variável de resposta contínua Y como uma função de uma ou mais variáveis X. Para que você possa usar esse modelo de regressão para prever o Y quando apenas o X é conhecido.

Esta equação matemática pode ser generalizada da seguinte forma:

$$ Y = \beta_{1} + \beta_{2} X + \epsilon $$
onde, β1 é o intercepto e β2 é o declive.

Coletivamente, eles são chamados de coeficientes de regressão e ϵ é o termo de erro, a parte de Y que o modelo de regressão é incapaz de explicar.


2. Exemplo de Problema
Para esta análise, usaremos o carsconjunto de dados que vem com R por padrão.

cars é um conjunto de dados interno padrão, que torna conveniente mostrar a regressão linear de maneira simples e fácil de entender.

Você pode acessar este conjunto de dados digitando carsem seu console R.

Você descobrirá que consiste em 50 observações (linhas) e 2 variáveis (colunas) - diste speed. Vamos imprimir as primeiras seis observações aqui.

cabeça ( carros ) #> velocidade dist #> 1 4 2 #> 2 4 10 #> 3 7 4 #> 4 7 22 #> 5 8 16 #> 6 9 10  # display the first 6 observations






O objetivo aqui é estabelecer uma equação matemática em distfunção de speed, assim você pode usá-lo para prever distquando apenas speedo carro é conhecido.

Portanto, é desejável construir um modelo de regressão linear com a variável de resposta como diste o preditor como speed.

Antes de começarmos a construir o modelo de regressão, é uma boa prática analisar e entender as variáveis.

A análise gráfica e o estudo de correlação abaixo ajudarão com isso.

3. Análise Gráfica
O objetivo deste exercício é criar um modelo de regressão simples que você possa usar para prever Distance ( dist).

Isso é possível estabelecendo uma fórmula matemática entre Distância ( dist) e Velocidade ( speed).

Mas antes de entrar na sintaxe, vamos tentar entender essas variáveis graficamente.

Normalmente, para cada um dos preditores, os seguintes gráficos ajudam a visualizar os padrões:

Gráfico de dispersão: visualize a relação linear entre o preditor e a resposta
Box plot: Para detectar quaisquer observações atípicas na variável. Ter outliers em seu preditor pode afetar drasticamente as previsões, pois elas podem afetar a direção / inclinação da linha de melhor ajuste.
Gráfico de densidade: para ver a distribuição da variável de previsão. Idealmente, é preferível uma distribuição próxima da normal (uma curva em forma de sino), sem ser inclinada para a esquerda ou para a direita.
Vamos ver como fazer cada um deles.

Usando o Gráfico de Dispersão para Visualizar o Relacionamento
Gráficos de dispersão podem ajudar a visualizar relacionamentos lineares entre as variáveis de resposta e de previsão.

Idealmente, se você tem muitas variáveis preditoras, um gráfico de dispersão é desenhado para cada uma delas em relação à resposta, junto com a linha de melhor ajuste, como visto abaixo.

dispersão . suave ( x = carros $ velocidade , y = carros $ dist , main = "Dist ~ Velocidade" )  # scatterplot
Distância Vs Scatterplot Speed
DISTÂNCIA VS SCATTERPLOT SPEED

O gráfico de dispersão junto com a linha de suavização acima sugere uma relação linear e positiva entre o ' dist' e ' speed'.

Isto é uma coisa boa.

Porque, uma das hipóteses subjacentes da regressão linear é, a relação entre as variáveis de resposta e preditor é linear e aditiva .

Usando BoxPlot para verificar outliers
Geralmente, um outlier é qualquer ponto de dados que esteja fora da faixa interquartil de 1,5 * (IQR).

O IQR é calculado como a distância entre os valores do 25º percentil e 75º percentil para essa variável.

par ( mfrow = c ( 1 , 2 ))   # divide graph area in 2 columns

Boxplot ( carros $ velocidade , main = "velocidade" , sub = colar ( "linhas Outlier:" , boxplot . stats ( carros velocidade $ ) $ out ))   # box plot for 'speed'

boxplot ( cars $ dist , main = "Distância" , sub = paste ( "Linhas de Outlier:" , boxplot . stats ( carros $ dist ) $ out ))   # box plot for 'distance'
Boxplots de Velocidade e Distância
BOXPLOTS DE VELOCIDADE E DISTÂNCIA


Usando o gráfico de densidade para verificar se a variável de resposta está próxima do normal
biblioteca ( e1071 ) 
par ( mfrow = c ( 1 , 2 ))  # for skewness function   # divide graph area in 2 columns

enredo ( densidade ( carros $ velocidade ), principal = "Densidade Plot: Speed" , ylab = "Frequência" , sub = pasta ( "assimetria:" , redondos ( e1071 :: assimetria ( carros $ velocidade ), 2 )))    # density plot for 'speed'

polígono ( densidade ( carros $ velocidade ), col = "vermelho" )

plot ( densidade ( carros $ dist ), principal = "Densidade Plot: Distância" , ylab = "Frequência" , sub = pasta ( "Assimetria:" , redondos ( e1071 :: assimetria ( carros $ dist ), 2 )))    # density plot for 'dist'

polígono ( densidade ( carros $ dist ), col = "red" )
Gráfico de densidade para velocidade e distância
GRÁFICO DE DENSIDADE PARA VELOCIDADE E DISTÂNCIA

4. O que é Análise de Correlação?
A análise de correlação estuda a força da relação entre duas variáveis contínuas. Envolve calcular o coeficiente de correlação entre as duas variáveis.

Então, o que é correlação? E como isso é útil na regressão linear?

Correlação é uma medida estatística que mostra o grau de dependência linear entre duas variáveis.

Para calcular a correlação, as duas variáveis devem ocorrer em pares, assim como o que temos aqui com speede dist.

Correlação pode levar valores entre -1 a +1.

Se uma variável aumenta consistentemente com o valor crescente da outra, então elas têm uma forte correlação positiva (valor próximo de +1).

Da mesma forma, se um diminui consistentemente quando o outro aumenta, eles têm uma forte correlação negativa (valor próximo de -1).

Um valor mais próximo de 0 sugere uma relação fraca entre as variáveis.

Uma baixa correlação (-0,2 <x <0,2) provavelmente sugere que grande parte da variação da variável resposta (Y) é inexplicada pelo preditor (X). Nesse caso, você provavelmente deve procurar por melhores variáveis explicativas.

Se você observar o carsconjunto de dados no console R, para cada instância em que a velocidade aumenta, a distância também aumenta junto com ela.

Isso significa que existe uma forte relação positiva entre eles. Então, a correlação entre eles será mais próxima de 1.

No entanto, a correlação não implica causalidade.

Em outras palavras, se duas variáveis têm alta correlação, isso não significa que uma variável "causa" o valor da outra variável a aumentar.

Correlação é apenas uma ajuda para entender o relacionamento. Você só pode confiar na lógica e no raciocínio comercial para fazer esse julgamento.

Então, como calcular a correlação em R?

Simplesmente use a função com as duas variáveis numéricas como argumentos.cor()

cor ( carros $ velocidade , carros $ dist ) #> [1] 0.8068949  # calculate correlation between speed and distance 
5. Construindo o Modelo de Regressão Linear
Agora que você viu o relacionamento linear pictoricamente no gráfico de dispersão e por meio de correlação, vamos tentar construir o modelo de regressão linear.

A função usada para construir modelos lineares é .lm()

A função lm () aceita dois argumentos principais:

Fórmula
Dados
Os dados são tipicamente um objeto e a fórmula é um objeto de classe .data.frameformula

Mas a convenção mais comum é escrever a fórmula diretamente conforme descrito abaixo.

linearMod <- lm ( dist ~ velocidade , dados = carros ) print ( linearMod ) #> Chamada: #> lm (formula = dist ~ velocidade, dados = carros) #> #> Coeficientes: #> (Intercept) velocidade   #> - 17,579 3,932  # build linear regression model on full data






Ao construir o modelo de regressão linear, estabelecemos a relação entre o preditor e a resposta na forma de uma fórmula matemática.

Isso é Distance ( dist) como uma função para speed.

Para a saída acima, você pode notar a parte 'Coefficients' tendo dois componentes: Intercept: -17.579, speed: 3.932.

Estes também são chamados de coeficientes beta . Em outras palavras,

$$ dist = Interceptar + (β ∗ velocidade) $$

=> dist = −17,579 + 3,932 ∗ de velocidade

6. Diagnóstico de regressão linear
Agora o modelo linear é construído e você tem uma fórmula que pode ser usada para prever o distvalor se um correspondente speedfor conhecido.

Isso é suficiente para realmente usar esse modelo? NÃO!

Porque, antes de usar um modelo de regressão para fazer previsões, você precisa garantir que seja estatisticamente significativo. Mas como você garante isso?

Vamos começar imprimindo as estatísticas de resumo para linearMod.

resumo ( linearMod ) #> Chamada: #> lm (fórmula = dist ~ velocidade, dados = carros) #> #> Resíduos: #> Mínimo 1T Mediana 3T Máx. #> -29.069 -9.525 -2.272 9.215 43.201 #> #> Coeficientes : #> Estimativa Std. Erro t valor Pr (> | t |)     #> (Interceptar) -17.5791 6.7584 -2.601 0.0123 *   #> velocidade 3.9324 0.4155 9.464 1.49e-12 *** #> --- #> Signif. códigos: 0 '***' 0,001 '**' 0,01 '*' 0,05 '.' 0,1 '' 1 #> #> Erro padrão residual: 15,38 em 48 graus de liberdade #> Múltiplo R-quadrado: 0,6511, R-quadrado ajustado: 0.  # model summary
















#> Estatística F: 89.57 em 1 e 48 DF, valor p: 1.49e-12
Usando o p valor para verificar a significância estatística
As estatísticas de resumo acima nos informam várias coisas.

Um deles é o p-Value do modelo (na última linha) e o p-Value das variáveis preditoras individuais (coluna extrema direita sob 'Coeficientes').

Os p-valores são muito importantes.

Porque, podemos considerar um modelo linear para ser estatisticamente significativo apenas quando ambos os p-valores são inferiores ao nível de significância estatístico pré-determinado de 0,05.

Isso pode ser interpretado visualmente pelas estrelas de significância no final da linha contra cada variável X.

Quanto mais as estrelas ao lado do p-Value da variável, mais significativa é a variável.

Qual é a hipótese nula e alternada?
Sempre que houver um valor p, há sempre uma hipótese nula e alternada associada.

Então, qual é a hipótese nula neste caso?

Em Regressão Linear, a Hipótese Nula (H0) é que os coeficientes beta associados às variáveis são iguais a zero.

A hipótese alternativa (H1) é que os coeficientes não são iguais a zero. (isto é, existe uma relação entre a variável independente em questão e a variável dependente).

Qual é o valor de t?
Podemos interpretar o valor-t algo assim. Um valor t maior indica que é menos provável que o coeficiente não seja igual a zero puramente por acaso. Então, quanto maior o valor de t, melhor.

Pr (> | t |) ou p-value é a probabilidade de você obter um valor t tão alto ou mais alto que o valor observado quando a hipótese nula (o coeficiente β é igual a zero ou que não há relacionamento) é verdadeira .

Portanto, se o Pr (> | t |) é baixo, os coeficientes são significativos (significativamente diferentes de zero). Se o Pr (> | t |) é alto, os coeficientes não são significativos.

O que isso significa para nós?

Quando p Value é menor que o nível de significância (<0,05), você pode rejeitar com segurança a hipótese nula de que o coeficiente β do preditor é zero.

No nosso caso, linearModambos os p-valores estão bem abaixo do limite de 0,05.

Assim, você pode rejeitar a hipótese nula e concluir que o modelo é de fato estatisticamente significativo.

É muito importante que o modelo seja estatisticamente significativo antes de você poder usá-lo para prever a variável dependente. Caso contrário, a confiança nos valores previstos desse modelo é reduzida e pode ser interpretada como um evento do acaso.

Como calcular a estatística t e p-valores?
Quando os coeficientes do modelo e o erro padrão são conhecidos, a fórmula para calcular a estatística t e o valor-p é a seguinte:

$$ t − Statistic = {β-coeficiente \ over Std.Error} $$

Caso você queira calcular algumas das estatísticas por código manual, o trecho abaixo mostra como.

# capture model summary as an object
modelSummary <- summary ( linearMod )  

# model coefficients
modelCoeffs <- modelSummary $ coefficients  

# get beta estimate for speed
beta . Estimativa <- modelCoeffs [ "speed" , "Estimativa" ] 

# get std.error for speed  
std . erro <- modelCoeffs [ "speed" , "Std. Error" ]   

# calc t statistic
t_value <- beta . estimativa / std . erro  

# calc p Value
p_value <- 2 * pt (- abs ( t_value ), df = nevo ( carros ) - ncol ( carros ))   

# fstatistic
f_statistic <- linearMod $ fstatistic [ 1 ]  

# parameters for model p-value calc
f <- summary ( linearMod ) $ fstatistic
  
model_p <- pf ( f [ 1 ], f [ 2 ], f [ 3 ], inferior = FALSE ) #> t Valor: 9.46399 #> p Valor: 1.489836e-12 #> Modelo F Estatística: 89.56711 1 48 #> Modelo p-Valor: 1,489836e-12



R-Quadrado e Adj R-Quadrado
A informação real em um dado é a variação total que ele contém, lembra ?.

O que R-Squared nos diz é a proporção de variação na variável dependente (resposta) que foi explicada por este modelo.

R Computação Quadrada
R COMPUTAÇÃO QUADRADA

Lembre-se de que a informação total em uma variável é a quantidade de variação que ela contém.

$$ R ^ {2} = 1 - \ frac {RSS} {TSS} $$

onde, RSS é a soma residual de quadrados dada por

$$ RSS = \ sum_ {i} ^ {n} \ left (y_ {i} - \ hat {y_ {i}} \ right) ^ {2} $$ 
e a soma do total ao quadrado é dada por 
$$ TSS = \ sum_ {i} ^ {n} \ left (y_ {i} - \ bar {y_ {i}} \ right) ^ {2} $$

Aqui, y-hat é o valor ajustado para observação i e y-bar é a média de Y.

Não descartamos necessariamente um modelo baseado em um valor baixo de R-Quadrado.

Para comparar a eficácia de dois modelos de regressão diferentes, é uma boa prática usar a amostra de validação para comparar a AIC dos dois modelos.

Além da AIC, outras métricas de avaliação, como erro percentual absoluto médio (MAPE), erro médio quadrático (MSE) e erro absoluto médio (MAE) também podem ser usadas.

Isso é sobre R-Squared. E quanto ao R-Squared ajustado?

O que é R-Squared ajustado?
À medida que você adiciona mais variáveis X ao seu modelo, o valor de R-Squared do novo modelo maior sempre será maior que o do subconjunto menor.

Você pode imaginar por quê?

Isso porque, como todas as variáveis do modelo original também estão presentes, sua contribuição para explicar a variável dependente também estará presente no superconjunto.

Portanto, qualquer nova variável adicionada só poderá adicionar (se não significativamente) à variação já explicada.

É aqui que o valor ajustado de R-Squared vem ajudar.

O R-Squared ajustado é formulado de forma a penalizar o número de termos (preditores de leitura) em seu modelo.

Portanto, ao contrário do R-sq, conforme o número de preditores no modelo aumenta, o adj-R-sq pode nem sempre aumentar.

Portanto, ao comparar modelos aninhados, é uma boa prática comparar usando adj-R-squared ao invés de apenas R-squared.

$$ R ^ {2} _ {adj} = 1 - \ frac {MSE} {MST} $$

onde, MSE é o erro quadrático médio dado por

$$ MSE = \ frac {RSS} {\ left (nq \ right)} $$

e MST é o total médio ao quadrado dado por

$$ MST = \ frac {TSS} {\ left (n-1 \ right)} $$

onde, n é o número de observações e q é o número de coeficientes no modelo.

Portanto, movendo-se em torno dos numeradores e denominadores, a relação entre R2 e Radj2 torna-se:

$$ R ^ {2} _ {adj} = 1 - \ left (\ frac {\ left (1 - R ^ {2} \ right) \ left (n-1 \ right)} {nq} \ right) $ $

Erro padrão e estatística F
Os erros padrão e a estatística F são medidas de adequação.

$$ Std. Erro = \ sqrt {MSE} = \ sqrt {\ frac {SSE} {nq}} $$

$$ F-statistic = \ frac {MSR} {MSE} $$

onde, n é o número de observações, q é o número de coeficientes e MSR é a média da regressão quadrada, calculada como,

$$ MSR = \ frac {\ sum_ {i} ^ {n} \ left (\ hat {y_ {i} - \ bar {y}} \ right)} {q-1} = \ frac {SST - SSE} {q - 1} $$

Quanto maior a estatística F, melhor é.

O que é AIC e BIC? 
O critério de informação de Akaike - AIC (Akaike, 1974) e o critério de informação Bayesiano - BIC (Schwarz, 1978) são medidas da adequação do ajuste do modelo de regressão linear e também podem ser usados para seleção de modelos.

Ambos os critérios dependem do valor maximizado da função de verossimilhança L para o modelo estimado.

O AIC é definido como:

AIC = (−2) × ln (L) + (2 × k)

onde, k é o número de parâmetros do modelo e o BIC é definido como:

BIC = (−2) × ln (L) + k × ln (n)

onde, n é o tamanho da amostra.

Para comparação de modelos, o modelo com menor pontuação de AIC e BIC é o preferido.

AIC ( linearMod ) # => 419.1569 
BIC ( linearMod ) # => BIC => 424.8929  
  
7. Como saber qual modelo de regressão é mais adequado para os dados?
As métricas mais comuns para olhar ao selecionar o modelo são:

ESTATÍSTICA	CRITÉRIO
R-Squared	Quanto mais alto melhor
Adj R-Squared	Quanto mais alto melhor
Estatística F	Quanto mais alto melhor
Std. Erro	Mais perto de zero, melhor
estatística t	Deve ser maior que 1,96 para o valor p ser menor que 0,05
AIC	Abaixe o melhor
BIC	Abaixe o melhor
Mallows cp	Deve estar próximo do número de preditores no modelo
MAPE (erro percentual absoluto médio)	Abaixe o melhor
MSE (erro quadrático médio)	Abaixe o melhor
Min_Max Precisão => média (min (atual, previsto) / max (atual, previsto))	Quanto mais alto melhor
8. Prevendo Modelos Lineares
Até agora você viu como construir um modelo de regressão linear usando todo o conjunto de dados. Se você construir dessa maneira, não há como dizer como o modelo será executado com novos dados.

Portanto, a prática preferida é dividir seu conjunto de dados em uma amostra de 80:20 (treinamento: teste) e, em seguida, construir o modelo na amostra de 80% e usar o modelo criado para prever a variável dependente nos dados de teste.

Fazendo desta forma, teremos os valores preditos do modelo para os 20% de dados (teste), bem como os valores reais (do conjunto de dados original).

Calculando as medidas de precisão (como a precisão min_max) e as taxas de erro (MAPE ou MSE), você pode descobrir a precisão da previsão do modelo.

Agora, vamos ver como realmente fazer isso.

Etapa 1: criar os dados de treinamento e teste
Isso pode ser feito usando a função. Apenas certifique-se de definir a semente usando para que as amostras possam ser recriadas para uso futuro.sample()set.seed()

# Create Training and Test data -
conjunto . semente ( 100 ) 
trainingRowIndex <- sample ( 1 : nrow ( carros ), 0,8 * nrow ( carros )) 
trainingData <- cars [ trainingRowIndex , ] 
testData   <- carros [- trainingRowIndex , ]  # setting seed to reproduce results of random sampling   # row indices for training data   # model training data    # test data
Etapa 2: ajustar o modelo nos dados de treinamento e prever distos dados de teste
# Build the model on training data
lmMod <- lm ( dist ~ speed , data = trainingData ) 
distPred <- predizer ( lmMod , testData )  # build the model  # predict distance
Etapa 3: Analise as medidas de diagnóstico.
resumo ( lmMod ) #> #> Chamada: #> lm (fórmula = dist ~ velocidade, dados = trainingData) #> #> Resíduos: #> Mínimo 1T Mediana 3T Máx. #> -23.350 -10.771 -2.137 9.255 42.231 #> # > Coeficientes: #> Estimativa Std. Erro t valor Pr (> | t |)     #> (Interceptar) -22.657 7.999 -2.833 0.00735 ** #> velocidade 4.316 0.487 8.863 8.73e-11 *** #> --- #> Signif. códigos: 0 '***' 0,001 '**' 0,01 '*' 0,05 '.' 0,1 '' 1 #> #> Erro padrão residual: 15,84 em 38 graus de liberdade #> Múltiplos R-quadrado: 0,674,  # model summary

















#> Estatística F: 78.56 em 1 e 38 DF, valor de p: 8.734e-11 
AIC ( lmMod ) #> [1] 338.4489  # Calculate akaike information criterion
A partir do resumo do modelo, o valor p do modelo e o valor p do preditor são menores que o nível de significância.

Então você tem um modelo estatisticamente significativo.

Além disso, o R-Sq e o Adj R-Sq são comparativos com o modelo original baseado em dados completos.

Etapa 4: calcular a precisão de previsão e as taxas de erro
Uma simples correlação entre os valores reais e previstos pode ser usada como uma forma de medida de precisão.

Uma maior precisão de correlação implica que os valores reais e previstos têm um movimento direcional similar, ou seja, quando os valores reais aumentam, os valores previstos também aumentam e vice-versa.

actuals_preds <- data . frame ( cbind ( actuals = testData $ dist , preditos = distPred )) 
correlation_accuracy <- cor ( actuals_preds ) 
cabeça ( actuals_preds ) #> factos previstos #> 1 2 -5.392776 #> 4 22 7.555787 #> 8 26 20.504349 #> 20 26 37.769100 #> 26 54 42.085287 #> 31 50 50.717663  # make actuals_predicteds dataframe.  # 82.7%






Agora vamos calcular a precisão mínima máxima e o MAPE:

$$ MinMaxAccuracy = mean \ left (\ frac {min \ left (efetivos, previstos \ right)} {max \ left (efetivos, previstos \ right)} \ right) $$

$$ MeanAbsolutePercentageError \ (MAPE) = média \ left (\ frac {abs \ left (preditos-reais \ right)} {actuals} \ right) $$

# Min-Max Accuracy Calculation
min_max_accuracy <- mean ( aplicar ( actuals_preds , 1 , min ) / aplicar ( actuals_preds , 1 , max )) # => 38.00%, precisão min_max     


# MAPE Calculation
mape <- mean ( abs (( props_preds $ predicts - actualspreds $ actuals )) / actualspreds $ actuals ) # => 69.95%, desvio percentual médio absoluto  
Como alternativa, você pode calcular todas as métricas de erro de uma só vez usando a função no pacote DMwR. Você terá que para isso, se você estiver usando pela primeira vez.regr.eval()install.packages('DMwR')

DMwR :: regr . eval ( actuals_preds $ actuals , actuals_preds $ previstos ) # => mae mse rmse mape # => 12.0082829 205.9652710 14.3514902 0.6995032


9. O que é a validação da Cruz Cruzada e seu Propósito?
Suponha que o modelo preveja satisfatoriamente a divisão de 20% (dados de teste), isso é suficiente para acreditar que seu modelo funcionará igualmente bem o tempo todo?

O que quero dizer com isso?

É possível que alguns dos pontos de dados não sejam representativos da população na qual o modelo foi construído.

Por exemplo, no conjunto de dados de carros, vamos supor que a estrada de concreto foi usada para os testes de estrada nos dados de treinamento de 80%, enquanto a estrada enlameada foi usada para os 20% restantes dos dados de teste.

Se o modelo foi treinado em tal configuração, você não pode esperar que o modelo preveja o distconjunto de dados de teste com igual precisão. Simplesmente porque, não aprendeu a relação entre speede distem tal cenário.

Portanto, é importante testar rigorosamente o desempenho do modelo o máximo possível.

Uma maneira de fazer esse teste rigoroso é verificar se a equação do modelo funciona igualmente bem, quando treinada e testada em diferentes partes distintas de dados.

Isso é exatamente o que a validação cruzada k-Fold faz. Aqui está como isso funciona:

1. Divida seus dados em porções de amostra aleatórias mutuamente exclusivas 'k'.

2. Em seguida, construa iterativamente k modelos, mantendo um dos subconjuntos-k como dados de teste de cada vez.

Em cada iteração, construímos o modelo nos dados restantes (k-1) e calculamos o erro quadrático médio das previsões no k-ésimo subconjunto.

3. Finalmente, calcula-se a média desses erros quadrados médios (para as porções 'k').

Você pode usar essa métrica para comparar diferentes modelos lineares.

Ao fazer isso, você precisa verificar duas coisas das previsões de k-fold:

Se a precisão de predição de cada modelo de dobra-k não for muito variável para qualquer amostra específica, e
Se as linhas de melhor ajuste das dobras em k não variam muito em relação à inclinação e ao nível.
Em outras palavras, eles devem ser paralelos e tão próximos uns dos outros quanto possível. Isto é o que o gráfico de validação cruzada k-fold (abaixo) revela.

biblioteca ( DAAG ) 
cvResults <- suppressWarnings ( CVlm ( df = carros , forma . lm = dist ~ velocidade , m = 5 , pontos = FALSO , semente = 29 , legend . pos = "topleft" ,   printit = FALSE , main = " Símbolos pequenos são valores previstos, enquanto os maiores são reais. " ));  # performs the CV
attr ( cvResults , 'ms' ) # => 251.2783 erro quadrático médio   
Na plotagem abaixo, as linhas tracejadas são paralelas? Os símbolos pequenos e grandes não estão dispersos por uma cor específica?

Gráfico de validação cruzada em R
GRÁFICO DE VALIDAÇÃO CRUZADA EM R

10. Onde ir a partir daqui?
Nós cobrimos os conceitos básicos sobre regressão linear. Além disso, você precisa entender que a regressão linear é baseada em certas suposições subjacentes que devem ser tomadas, especialmente quando se trabalha com múltiplos Xs. Quando você estiver familiarizado com isso, os modelos de regressão avançados mostrarão os vários casos especiais em que uma forma diferente de regressão seria mais adequada.